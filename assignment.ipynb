{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eded38a1",
   "metadata": {},
   "source": [
    "# Assignment 6: Neural Network Showdown\n",
    "\n",
    "Build and compare neural network architectures on image and time-series data.\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8249dd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import (\n",
    "    Dense, Flatten, Dropout, Conv2D, MaxPooling2D, LSTM, Input\n",
    ")\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from helpers import (\n",
    "    load_cifar10, load_ecg5000,\n",
    "    plot_training_history, plot_confusion_matrix,\n",
    "    CIFAR10_CLASSES, ECG_CLASSES,\n",
    ")\n",
    "\n",
    "OUTPUT_DIR = \"output\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d449f3e9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Dense Baseline on CIFAR-10\n",
    "\n",
    "**Task:** Build a Dense (fully connected) network to classify CIFAR-10 images.\n",
    "\n",
    "CIFAR-10 has 60,000 color images (32x32x3) across 10 classes. A Dense network\n",
    "flattens each image into 3,072 numbers and classifies from there. This is our\n",
    "baseline — it ignores spatial structure entirely.\n",
    "\n",
    "**Architecture requirements:**\n",
    "- Flatten the input\n",
    "- At least 2 hidden Dense layers with ReLU activation\n",
    "- Dropout after each hidden layer\n",
    "- Output: Dense(10, softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df38792",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Part 1: Dense Baseline on CIFAR-10\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Load data (normalized to [0,1], one-hot encoded)\n",
    "X_train, y_train, X_test, y_test = load_cifar10()\n",
    "print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22c7da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Build a Dense model using Sequential\n",
    "# Requirements:\n",
    "#   - Input(shape=(32, 32, 3))\n",
    "#   - Flatten()\n",
    "#   - At least 2 Dense hidden layers with activation='relu'\n",
    "#   - Dropout after each hidden Dense layer\n",
    "#   - Dense(10, activation='softmax') as output\n",
    "model_dense = None  # replace with your Sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a8c7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compile the model\n",
    "# model_dense.compile(optimizer='adam',\n",
    "#                     loss='categorical_crossentropy',\n",
    "#                     metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a895ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train with EarlyStopping\n",
    "# early_stop = EarlyStopping(monitor='val_loss', patience=3,\n",
    "#                            restore_best_weights=True)\n",
    "# history_dense = model_dense.fit(X_train, y_train,\n",
    "#                                 epochs=20, batch_size=128,\n",
    "#                                 validation_split=0.1,\n",
    "#                                 callbacks=[early_stop])\n",
    "history_dense = None  # replace with your fit call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a684cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluate on test set\n",
    "# test_loss, test_acc = model_dense.evaluate(X_test, y_test, verbose=0)\n",
    "test_acc = None  # replace\n",
    "\n",
    "# TODO: Generate predictions and confusion matrix\n",
    "# y_pred = np.argmax(model_dense.predict(X_test, verbose=0), axis=1)\n",
    "# y_true = np.argmax(y_test, axis=1)\n",
    "# cm = confusion_matrix(y_true, y_pred)\n",
    "y_pred = None  # replace\n",
    "y_true = None  # replace\n",
    "cm = None  # replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0194aa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results (do not modify this cell)\n",
    "results = {\n",
    "    \"accuracy\": float(test_acc),\n",
    "    \"confusion_matrix\": cm.tolist(),\n",
    "}\n",
    "with open(os.path.join(OUTPUT_DIR, \"part1_results.json\"), \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"Dense accuracy: {test_acc:.4f}\")\n",
    "print(\"Saved output/part1_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ccd325",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: CNN on CIFAR-10\n",
    "\n",
    "**Task:** Build a CNN to classify the same CIFAR-10 images. Compare its accuracy\n",
    "to the Dense baseline from Part 1.\n",
    "\n",
    "CNNs use convolutional filters that slide across the image, detecting local\n",
    "patterns (edges, textures, shapes). This preserves spatial structure that\n",
    "Dense layers discard.\n",
    "\n",
    "**Architecture requirements:**\n",
    "- At least 2 Conv2D + MaxPooling2D blocks\n",
    "- Flatten, then Dense hidden layer with Dropout\n",
    "- Output: Dense(10, softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8253500",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPart 2: CNN on CIFAR-10\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Data is already loaded from Part 1 (X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305791e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Build a CNN model using Sequential\n",
    "# Requirements:\n",
    "#   - Input(shape=(32, 32, 3))\n",
    "#   - At least 2 blocks of: Conv2D(filters, (3,3), activation='relu')\n",
    "#                            + MaxPooling2D((2,2))\n",
    "#   - Flatten()\n",
    "#   - Dense hidden layer with ReLU + Dropout\n",
    "#   - Dense(10, activation='softmax') as output\n",
    "model_cnn = None  # replace with your Sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a629c446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compile the model\n",
    "# model_cnn.compile(optimizer='adam',\n",
    "#                   loss='categorical_crossentropy',\n",
    "#                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c481c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train with EarlyStopping and ModelCheckpoint\n",
    "# callbacks = [\n",
    "#     EarlyStopping(monitor='val_loss', patience=3,\n",
    "#                   restore_best_weights=True),\n",
    "#     ModelCheckpoint('output/best_cnn.keras',\n",
    "#                     save_best_only=True, monitor='val_accuracy'),\n",
    "# ]\n",
    "# history_cnn = model_cnn.fit(X_train, y_train,\n",
    "#                             epochs=15, batch_size=64,\n",
    "#                             validation_split=0.1,\n",
    "#                             callbacks=callbacks)\n",
    "history_cnn = None  # replace with your fit call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5065b020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot training history\n",
    "# plot_training_history(history_cnn,\n",
    "#                       os.path.join(OUTPUT_DIR, \"part2_training_history.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177c8282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluate on test set\n",
    "# cnn_loss, cnn_acc = model_cnn.evaluate(X_test, y_test, verbose=0)\n",
    "cnn_acc = None  # replace\n",
    "\n",
    "# TODO: Generate predictions and confusion matrix\n",
    "# y_pred_cnn = np.argmax(model_cnn.predict(X_test, verbose=0), axis=1)\n",
    "# y_true_cnn = np.argmax(y_test, axis=1)\n",
    "# cm_cnn = confusion_matrix(y_true_cnn, y_pred_cnn)\n",
    "y_pred_cnn = None  # replace\n",
    "y_true_cnn = None  # replace\n",
    "cm_cnn = None  # replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221177b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results (do not modify this cell)\n",
    "results_cnn = {\n",
    "    \"accuracy\": float(cnn_acc),\n",
    "    \"confusion_matrix\": cm_cnn.tolist(),\n",
    "}\n",
    "with open(os.path.join(OUTPUT_DIR, \"part2_results.json\"), \"w\") as f:\n",
    "    json.dump(results_cnn, f, indent=2)\n",
    "\n",
    "comparison = pd.DataFrame([\n",
    "    {\"model\": \"Dense\", \"accuracy\": float(test_acc)},\n",
    "    {\"model\": \"CNN\", \"accuracy\": float(cnn_acc)},\n",
    "])\n",
    "comparison.to_csv(os.path.join(OUTPUT_DIR, \"part2_comparison.csv\"), index=False)\n",
    "\n",
    "print(f\"CNN accuracy:   {cnn_acc:.4f}\")\n",
    "print(f\"Dense accuracy: {test_acc:.4f}\")\n",
    "print(f\"Improvement:    {cnn_acc - test_acc:+.4f}\")\n",
    "print(\"Saved output/part2_results.json and output/part2_comparison.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c11c33",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: LSTM on ECG5000\n",
    "\n",
    "**Task:** Build an LSTM to classify heartbeat recordings.\n",
    "\n",
    "ECG5000 contains 5,000 heartbeat recordings — each is 140 time steps of voltage\n",
    "measurements, classified into 5 types (Normal, Supraventricular, Premature\n",
    "Ventricular, Fusion, Unknown). This is sequential data where order matters,\n",
    "making it a natural fit for recurrent networks.\n",
    "\n",
    "**Architecture requirements:**\n",
    "- LSTM layer (any reasonable number of units)\n",
    "- Dropout for regularization\n",
    "- Dense output with softmax (5 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b371fb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPart 3: LSTM on ECG5000\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Load ECG data (already shaped for RNN input)\n",
    "X_train_ecg, y_train_ecg, X_test_ecg, y_test_ecg = load_ecg5000()\n",
    "print(f\"Train: {X_train_ecg.shape}, Test: {X_test_ecg.shape}\")\n",
    "print(f\"Classes: {list(ECG_CLASSES.values())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bdb741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Build an LSTM model using Sequential\n",
    "# Requirements:\n",
    "#   - Input(shape=(140, 1))\n",
    "#   - LSTM layer (e.g., 64 units)\n",
    "#   - Dropout\n",
    "#   - Dense(5, activation='softmax')\n",
    "model_lstm = None  # replace with your Sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bddfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compile the model\n",
    "# model_lstm.compile(optimizer='adam',\n",
    "#                    loss='categorical_crossentropy',\n",
    "#                    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42df9716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train with EarlyStopping\n",
    "# early_stop = EarlyStopping(monitor='val_loss', patience=5,\n",
    "#                            restore_best_weights=True)\n",
    "# history_lstm = model_lstm.fit(X_train_ecg, y_train_ecg,\n",
    "#                               epochs=30, batch_size=32,\n",
    "#                               validation_split=0.1,\n",
    "#                               callbacks=[early_stop])\n",
    "history_lstm = None  # replace with your fit call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3adb9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot training history\n",
    "# plot_training_history(history_lstm,\n",
    "#                       os.path.join(OUTPUT_DIR, \"part3_training_history.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9a0dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluate on test set\n",
    "# lstm_loss, lstm_acc = model_lstm.evaluate(X_test_ecg, y_test_ecg, verbose=0)\n",
    "lstm_acc = None  # replace\n",
    "\n",
    "# TODO: Generate predictions and confusion matrix\n",
    "# y_pred_ecg = np.argmax(model_lstm.predict(X_test_ecg, verbose=0), axis=1)\n",
    "# y_true_ecg = np.argmax(y_test_ecg, axis=1)\n",
    "# cm_ecg = confusion_matrix(y_true_ecg, y_pred_ecg)\n",
    "y_pred_ecg = None  # replace\n",
    "y_true_ecg = None  # replace\n",
    "cm_ecg = None  # replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511b5aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results (do not modify this cell)\n",
    "results_ecg = {\n",
    "    \"accuracy\": float(lstm_acc),\n",
    "    \"confusion_matrix\": cm_ecg.tolist(),\n",
    "}\n",
    "with open(os.path.join(OUTPUT_DIR, \"part3_results.json\"), \"w\") as f:\n",
    "    json.dump(results_ecg, f, indent=2)\n",
    "\n",
    "print(f\"LSTM accuracy: {lstm_acc:.4f}\")\n",
    "print(\"Saved output/part3_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161442d5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515e3877",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nAll parts complete!\")\n",
    "print(\"Run 'pytest .github/tests/ -v' in your terminal to check your work.\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
